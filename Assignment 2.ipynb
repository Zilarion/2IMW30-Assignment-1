{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Foundations of Data Mining: Assignment 2\n",
    "\n",
    "Please complete all assignments in this notebook. You should submit this notebook, as well as a PDF version (See File > Download as)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from preamble import *\n",
    "plt.rcParams['savefig.dpi'] = 100 # This controls the size of your figures\n",
    "# Comment out and restart notebook if you only want the last output of each cell.\n",
    "InteractiveShell.ast_node_interactivity = \"none\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We load in our key by placing it in ~/.openml/config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Kernel selection (4 points (1+2+1))\n",
    "SVMs can be trained with different kernels. Generate a 2-dimensional dataset as shown below and study the effect of the choice of kernel by visualizing the results.\n",
    "\n",
    "- Train a SVM classifier on the dataset using respectively a linear, polynomial and radial basis function (RBF) kernel, evaluate the performance of each kernel using 10-fold cross-validation and AUC. Which one works best? Visualize the results. Can you intuitively explain why one kernel is more suited than another?\n",
    "    - Hint: you can use the visualization code used in class. It is under mglearn/plot_svm.py > plot_svm_kernels().\n",
    "- Take the RBF kernel and vary both the C parameter and the kernel width ($\\gamma$). Use 3 values for each (a very small, default, and very large value). For each of the 9 combinations, create the same RBF plot as before, report the number of support vectors, and the AUC performance. Explain the performance results. When are you over/underfitting?\n",
    "    - Hint: values for C and $\\gamma$ are typically in [$2^{-15}..2^{15}$] on a log scale. \n",
    "    - Hint: don't count the support vectors manually, retrieve them from the trained SVM.\n",
    "- Vary C and $\\gamma$ again, but this time use a grid of at least 20x20, vary both parameters uniformly on a log scale, and visualise the results using a $C \\times \\gamma \\rightarrow AUC$ heatmap. Explain the performance results, and compare them to the 9 results obtained in the previous subquestion. Can you also tell in which regions of the heatmap you are over/underfitting?\n",
    "    - Hint: We've constructed such a heatmap in class and in assignment 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X, y = make_blobs(centers=2, n_samples=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Robots and SVMs (4 points (2+1+1))\n",
    "\n",
    "The [Wall Robot Navigation dataset](http://www.openml.org/d/1497) contains about 5500 readings of an ultrasound sensor array mounted on a robot, and your task is to finetune and train an SVM classifier to predict how the robot should move next.\n",
    "\n",
    "- Make a stratified 80-20 split of the data. On the training set alone, optimize the main hyperparameters of the SVM for Accuracy with a random search. Vary at least the main kernel types (linear, polynomial, and RBF), the C parameter, the $\\gamma$ parameter for the RBF kernel and the exponent/degree for the polynomial kernel. Report the optimal hyperparameter settings and Accuracy performance. \n",
    "    - The degree of the polynonial is typically in the range 2..10.\n",
    "    - Hint: note that the hyperparameter ranges depend on each other. For instance, $\\gamma$ only makes sense if you have selected the RBF kernel as well. We've seen in class how to define multiple hyperparameter spaces in a random/grid search.\n",
    "- Use a 5x3-fold (5 outer, 3 inner) nested cross-validation (CV) on the training set to obtain a clean evaluation. Evaluate your optimized hyperparameter settings on the separate test set and discuss the result. Is the performance on the independent test set comparable with the result of the random search?\n",
    "    - Hint: for the nested resampling, use at least a 10-fold CV for the outer loop. The inner loop can be a 3-fold CV or a simple holdout.\n",
    "- Train an SVM using the optimal hyperparameter configuration you found and test it on the held out (20%) test set. Compare this Accuracy result with the (mean) result of the nested CV. If you would build this robot in practice, how would you find the hyperparameters to use, and which performance would you expect? Is it truly necessary to tune the hyperparameters? Which hyperparameters were most important to tune?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "robot_data = oml.datasets.get_dataset(1497) # Download Robot data\n",
    "# Get the predictors X and the labels y\n",
    "X, y = robot_data.get_data(target=robot_data.default_target_attribute); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## A benchmark study (3 points (2+1))\n",
    "\n",
    "A benchmark study is an experiment in which multiple algorithms are evaluated on multiple datasets. The end goal is to study whether one algorithm is generally better than the others. Meaningful benchmark studies can grow quite complex, here we do a simplified variant.\n",
    "\n",
    "* Download OpenML datasets 37, 470, 1120, 1464 and 1471. They are sufficiently large (e.g., at least 500 data points) so that the performance estimation is trustworthy. Select at least three classifiers that we discussed in class, e.g. kNN, Logistic Regression, Random Forests, Gradient Boosting, SVMs, Naive Bayes. Note that some of these algorithms take longer to train. Evaluate all classifiers (with default parameter settings) on all datasets, using a 10-fold CV and AUC. Show the results in a table and interpret them. Which is the best algorithm in this benchmark?\n",
    "    * Note that these datasets have categorical features, different scales, missing values, and (likely) irrelevant features. You'll need to build pipelines to correctly build all models. Also remove any row identifiers (see, e.g., https://www.openml.org/d/1120)\n",
    "    * Hint: You can either compare the performances directly, or (better) use a statistical significance test, e.g. a pairwise t-test or (better) Wilcoxon signed ranks test, to see whether the performance differences are significant. This is covered in statistics courses. You can then count wins, ties and losses.\n",
    "* Repeat the benchmark, but now additionally optimize the main hyperparameters of each algorithm in a grid or random search (explore at least 5 values per hyperparameter, where possible). Does this affect the ranking of the algorithms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define datasets and base classifiers\n",
    "datasets = [37, 470, 1120, 1464, 1471]\n",
    "\n",
    "# Create kf\n",
    "kf = StratifiedKFold(n_splits=10, random_state=2)\n",
    "\n",
    "# Create imputer to pre-process data\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "\n",
    "# Create scaler for the classifiers which need this\n",
    "scaler = StandardScaler()\n",
    "\n",
    "pipelines = [\n",
    "    Pipeline([(\"imputer\",imp), (\"scaler\", scaler), (\"classifier\", neighbors.KNeighborsClassifier())]),\n",
    "    Pipeline([(\"imputer\",imp), (\"scaler\", scaler), (\"classifier\", LogisticRegression())]),\n",
    "    Pipeline([(\"imputer\",imp), (\"classifier\", RandomForestClassifier())])\n",
    "]\n",
    "\n",
    "# Define parameter grids for the classifiers\n",
    "param_grids = [\n",
    "    {'classifier__n_neighbors': [1, 3, 5, 7, 9, 11, 33]}, \n",
    "    {'classifier__C': [0.001, 0.01, 1, 10, 100, 1000] },\n",
    "    {'classifier__max_features': list(range(1,5)), 'classifier__n_estimators': [1, 2, 4, 8, 16, 32, 64]}\n",
    "]\n",
    "\n",
    "# Score dicts\n",
    "dsScores = {}\n",
    "dsGridScores = {}\n",
    "\n",
    "# Process each dataset\n",
    "for dindex in datasets:\n",
    "    # Load data\n",
    "    data_set = oml.datasets.get_dataset(dindex)\n",
    "    X, y = data_set.get_data(target=data_set.default_target_attribute)\n",
    "    \n",
    "    scores = {}\n",
    "    gridScores = {}\n",
    "    # Run each clf using the corresponding parameter grid\n",
    "    for pipe, grid in zip(pipelines, param_grids):\n",
    "        # Run 10-fold pipeline\n",
    "        score = cross_val_score(pipe, X, y, cv=kf, n_jobs=8, scoring=\"roc_auc\").mean()\n",
    "        scores[clf.__class__.__name__] = score;\n",
    "\n",
    "        # Run gridsearch pipeline\n",
    "        gs = GridSearchCV(pipe, grid, cv=kf, n_jobs=8)\n",
    "        gs.fit(X, y)\n",
    "        results = pd.DataFrame(gs.cv_results_)\n",
    "        gridScores[clf.__class__.__name__] = gs.best_score_\n",
    "\n",
    "    dsScores[dindex] = scores\n",
    "    dsGridScores[dindex] = gridScores\n",
    "\n",
    "# Print default classifier scores\n",
    "print(\"Default scores:\")\n",
    "print(pd.DataFrame.from_dict(dsScores))\n",
    "\n",
    "# Print best grid scores\n",
    "print(\"\\nOptimized grid scores:\")\n",
    "print(pd.DataFrame.from_dict(dsGridScores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Gaussian Processes (2 points (1+1))\n",
    "\n",
    "Consider the RAM prices dataset (included in the data folder). Separate the data in a training set of all data points up until the year 2000, and a test set with all points after that.\n",
    "\n",
    "- Train several of the algorithms we have covered in the course that can handle regression. Include at least linear regression, decision tree, and RandomForest. Which ones give the best $R^2$ performance on the test set? Plot the predictions (both on the training and test data) on the figure below. Use different colors for different algorithms or build multiple plots.\n",
    "- Train a Gaussian process on an increasing amount of samples of the training data. Start with 5 random sample and plot the predictions (both the mean and the uncertainty interval) for both training and test data, as shown in class. Now add 5 more points and retrain and redraw. Do this a couple of times and interpret/explain what you see. Finally, train the Gaussian on the full dataset and again show plot the predictions. Evaluate on the test set using  $R^2$. Compare these results with those achieved with other algorithms and explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.as_matrix of 0      1957.00\n",
      "1      1959.00\n",
      "2      1960.00\n",
      "3      1965.00\n",
      "4      1970.00\n",
      "5      1973.00\n",
      "6      1974.00\n",
      "7      1975.00\n",
      "8      1975.08\n",
      "9      1975.25\n",
      "10     1975.75\n",
      "11     1976.00\n",
      "12     1976.17\n",
      "13     1976.42\n",
      "14     1976.58\n",
      "15     1977.08\n",
      "16     1978.17\n",
      "17     1978.25\n",
      "18     1978.33\n",
      "19     1978.50\n",
      "20     1978.58\n",
      "21     1978.75\n",
      "22     1979.00\n",
      "23     1979.75\n",
      "24     1980.00\n",
      "25     1981.00\n",
      "26     1981.58\n",
      "27     1982.00\n",
      "28     1982.17\n",
      "29     1982.67\n",
      "        ...   \n",
      "172    1997.25\n",
      "173    1997.33\n",
      "174    1997.42\n",
      "175    1997.50\n",
      "176    1997.58\n",
      "177    1997.67\n",
      "178    1997.75\n",
      "179    1997.83\n",
      "180    1997.92\n",
      "181    1998.00\n",
      "182    1998.08\n",
      "183    1998.17\n",
      "184    1998.25\n",
      "185    1998.33\n",
      "186    1998.42\n",
      "187    1998.58\n",
      "188    1998.67\n",
      "189    1998.75\n",
      "190    1998.83\n",
      "191    1998.92\n",
      "192    1999.08\n",
      "193    1999.13\n",
      "194    1999.17\n",
      "195    1999.25\n",
      "196    1999.33\n",
      "197    1999.50\n",
      "198    1999.67\n",
      "199    1999.75\n",
      "200    1999.83\n",
      "201    1999.92\n",
      "Name: date, dtype: float64>\n"
     ]
    },
    {
     "data": {
      "application/pdf": "JVBERi0xLjQKJazcIKu6CjEgMCBvYmoKPDwgL1R5cGUgL0NhdGFsb2cgL1BhZ2VzIDIgMCBSID4+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\nYXJ0eHJlZgoxMjg5NAolJUVPRgo=\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAADRCAYAAAB1sYEuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nz65EcAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ae3f940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "ram_prices = pd.read_csv('data/ram_price.csv')\n",
    "\n",
    "plt.semilogy(ram_prices.date, ram_prices.price)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Price in $/Mbyte\");\n",
    "\n",
    "train = ram_prices.query(\"date < 2000\")\n",
    "test = ram_prices.query(\"date >= 2000\")\n",
    "\n",
    "print (train.date.array)\n",
    "algorithms = [LinearRegression(), RandomForestRegressor(), DecisionTreeRegressor()]\n",
    "\n",
    "# for alg in algorithms:\n",
    "#     alg.fit(train.date, train.price)\n",
    "#     print(alg.score(test.date, test.price))\n",
    "#     print(cross_val_score(alg, ram_prices.date, ram_prices.price, cv=10, scoring=\"r2\").mean())\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## A mini-data mining challenge (2 points (+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The goal here is to use everything you have learned to build the best model for a given classification task. The task is hosted on OpenML, so you will receive the train-test splits, and your model will be evaluated on the server. The goal is to reasonably select algorithms and hyperparameter settings to obtain the best model. You can also do model selection and parameter optimization as you have done before. Skeleton code is provided in the OpenML tutorial.\n",
    "\n",
    "- All details can be found online:\n",
    "    - The OpenML Task ID is 145677: https://www.openml.org/t/145677\n",
    "    - The dataset description can be found here: https://www.openml.org/d/4134\n",
    "- A leaderboard is kept of the best models: https://www.openml.org/t/145677#!people\n",
    "    - You are able to see the solutions of others (by clicking in the timeline or run list), but resubmission of the exact same solution does not register on the leaderboard.\n",
    "    - You can share one account (one API key) per team. In case you use two, we take the one that performs best.\n",
    "- You can document the different experiments that you ran in this notebook. For each experiment, provide a description of how you chose the algorithms and parameters that you submitted. Try to reason about which experiments to try, don't just do an immense random search.\n",
    "- Points are rewarded as follows:\n",
    "    - 1 point for the breadth of experiments you ran (algorithms, hyperparameter settings)\n",
    "    - 1 point for reasoning/insight and interpretation of the results\n",
    "    - 1 (bonus) point for every team who has uploaded the best solution thus far **on AUC** (who reaches the top of the leaderboard at any moment during the assignment)\n",
    "        - Note: On the leaderboard page, the 'frontier' line is drawn, and your top ranking is also shown in the table.\n",
    "        \n",
    "Note: Report AUC scores in your report as well. In case of issues with OpenML we will use the experiments and scores mentioned your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import openml as oml\n",
    "\n",
    "# Load task data\n",
    "task = oml.tasks.get_task(145677)\n",
    "data = oml.datasets.get_dataset(task.dataset_id)\n",
    "X, y = data.get_data(target=data.default_target_attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We have lots of features (1777) Hence, we should either figure something out to reduce the amount features, or use a classifier which handles a lot of features well. Initially, our thoughts fell on using a random forest classifier without selecting features (this is what the decision trees do themselves anyhow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running..\n",
      "Publishing run\n",
      "RF on Bioresponse: http://www.openml.org/r/1849099\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectPercentile, SelectFromModel, RFE\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# We don't need a scalar since the dataset is already normalized\n",
    "\n",
    "# Create classifier\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=2048, min_samples_split=4, criterion=\"entropy\", n_jobs=-1)\n",
    "\n",
    "# Build pipeline\n",
    "pipe = Pipeline([\n",
    "    ('classifier', clf)\n",
    "])\n",
    "\n",
    "task = oml.tasks.get_task(145677)\n",
    "print(\"Running..\")\n",
    "run = oml.runs.run_task(task, pipe)\n",
    "print(\"Publishing run\")\n",
    "myrun = run.publish()\n",
    "print(\"RF on %s: http://www.openml.org/r/%d\" % (data.name, myrun.run_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This result was decent, but we did not find any way to significantly improve this. Hence, we now attempted to use logistic regression. But we still wanted to keep the performance from the RandomForest classifier. Hence we used this as the feature selector before we ran the LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 75 candidates, totalling 750 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done 750 out of 750 | elapsed: 43.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.859742509623\n",
      "{'classifier__gamma': 0.01, 'classifier__C': 10, 'classifier__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create feature selector \n",
    "fs = SelectFromModel(RandomForestClassifier(random_state=1, criterion=\"entropy\"))\n",
    "\n",
    "# Create default classifier\n",
    "clf = SVC()\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('feature_select', fs),\n",
    "    ('classifier', clf)\n",
    "])\n",
    "\n",
    "grid = {\n",
    "    \"classifier__C\": [0.01, 0.1, 1, 10, 100],\n",
    "    \"classifier__kernel\": [\"linear\", \"poly\", \"rbf\"],\n",
    "    \"classifier__gamma\": [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "gs = GridSearchCV(pipe, grid, cv=10, n_jobs=-1, scoring=\"roc_auc\", verbose=1)\n",
    "gs.fit(X, y)\n",
    "\n",
    "print(gs.best_score_)     \n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The results from this classification where significantly higher then we expected.\n",
    "Therefore we attempted to improve the best results further by increasing the number of estimators of the random forest classifier. And to optimize only the rbf kernel further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running..\n",
      "Publishing run\n",
      "RF on Bioresponse: http://www.openml.org/r/1849100\n"
     ]
    }
   ],
   "source": [
    "# Create feature selector \n",
    "fs = SelectFromModel(RandomForestClassifier(random_state=1, n_estimators=256, criterion=\"entropy\"))\n",
    "\n",
    "# Create default classifier\n",
    "clf = SVC(kernel=\"rbf\", C=10, gamma=0.01)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('feature_select', fs),\n",
    "    ('classifier', clf)\n",
    "])\n",
    "\n",
    "task = oml.tasks.get_task(145677)\n",
    "print(\"Running..\")\n",
    "run = oml.runs.run_task(task, pipe)\n",
    "print(\"Publishing run\")\n",
    "myrun = run.publish()\n",
    "print(\"SVM on %s: http://www.openml.org/r/%d\" % (data.name, myrun.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
